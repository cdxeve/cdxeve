# Daixuan Cheng

- I am a Ph.D. student at **Gaoling School of AI, Renmin University of China**, fortunately advised by [Xin Zhao](https://scholar.google.com/citations?user=JNhNacoAAAAJ&hl=en).  

- Ever Since 2021, I have been a research student advised by [Shaohan Huang](https://buaahsh.github.io) and [Furu Wei](https://thegenerality.com) from the **GenAI Group of Microsoft Research**, with whom I have accomplished many of my representative works.

- I was previously a research assistant in the **CoAI Group, Tsinghua University**, fortunately advised by [Yuxian Gu](https://t1101675.github.io) and [Minlie Huang](https://scholar.google.com/citations?user=P1jPSzMAAAAJ&hl=zh-CN).  I also worked as a research engineer at BIGAI, fortunately collaborating with [Xuekai Zhu](https://xuekai-zhu.github.io/Xuekai-Zhu/).

üåü **Recent Focus:**  
üåü My current research emphasizes **Reinforcement Learning for LLM Reasoning**, especially the **Exploration Mechanisms**!  
üåü Check out our works: üöÄ [Reasoning with Exploration: An Entropy Perspective](https://arxiv.org/abs/2506.14758), [FlowRL](https://huggingface.co/papers/2509.15207) and [STILL](https://github.com/RUCAIBox/Slow_Thinking_with_LLMs).  
üåü Feel free to reach out if you are interested in collaboration or discussions!

## Contact  
- ‚úâÔ∏è Email: [daixuancheng6@gmail.com](mailto:daixuancheng6@gmail.com)  

## Education

- **Ph.D. Student in Artificial Intelligence**, Gaoling School of AI, Renmin University of China (2025 ‚Äì Present)  
  - Advisor: [Xin Zhao](https://scholar.google.com/citations?user=JNhNacoAAAAJ&hl=en)

- **M.S. in Computer Science**, School of Computer Science, Beijing University of Posts and Telecommunications (2020 ‚Äì 2023)  
  - Advisor: [Haifeng Sun](https://hfsun.github.io)

- **B.S. in Communication Engineering**, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications (2016 ‚Äì 2020)  

## Research Interests  

I am dedicated to enhancing **Large Language Models (LLMs)** across their entire lifecycle, including:  
- **Reasoning and Reinforcement Learning**: [Reasoning with Exploration](https://arxiv.org/abs/2506.14758), [FlowRL](https://huggingface.co/papers/2509.15207), [STILL](https://github.com/RUCAIBox/Slow_Thinking_with_LLMs).  
- **Pre-training**: [Instruction Pre-Training](https://huggingface.co/papers/2406.14491), [AdaptLLM](https://huggingface.co/papers/2309.09530), [VL-Match](https://openaccess.thecvf.com/content/ICCV2023/papers/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.pdf).  
- **Domain Adaptation**: [AdaptLLM](https://huggingface.co/papers/2309.09530), [AdaMLLM](https://arxiv.org/abs/2411.19930), [SODA](https://aclanthology.org/2022.findings-emnlp.163/).  
- **Synthetic Data**: [Instruction Pre-Training](https://huggingface.co/papers/2406.14491), [AdaptLLM](https://huggingface.co/papers/2309.09530), [ToEdit](https://arxiv.org/abs/2412.14689).  
- **Retrieval Augmented Generation**: [UPRISE](https://arxiv.org/abs/2303.08518), [MDR](https://aclanthology.org/2024.naacl-long.235/).

## Selected Papers

*(Full list on [Google Scholar](https://scholar.google.com/citations?hl=en&user=flRAZJQAAAAJ&view_op=list_works))*

* **Reasoning with Exploration: An Entropy Perspective**  
  **Daixuan Cheng**, Shaohan Huang, Xuekai Zhu, Bo Dai, Wayne Xin Zhao, Zhenliang Zhang, Furu Wei  
  (**arXiv Preprint, 2025 ‚Äî üåü The earliest research on exploration-based RLVR in LLM reasoning**) [pdf](https://arxiv.org/abs/2506.14758)

* **FlowRL: Matching Reward Distributions for LLM Reasoning**  
  Xuekai Zhu, **Daixuan Cheng**, Dinghuai Zhang, Hengli Li, Kaiyan Zhang, Che Jiang, Youbang Sun, Ermo Hua, Yuxin Zuo, Xingtai Lv, Qizheng Zhang, Lin Chen, Fanghao Shao, Bo Xue, Yunchong Song, Zhenjie Yang, Ganqu Cui, Ning Ding, Jianfeng Gao, Xiaodong Liu, Bowen Zhou, Hongyuan Mei, Zhouhan Lin  
  (**arXiv Preprint, 2025 ‚Äî Exploration of RLVR in LLM reasoning, [ü§ó #1 Paper of the Day](https://huggingface.co/papers/2509.15207)**) [pdf](https://huggingface.co/papers/2509.15207) [code](https://github.com/Xuekai-Zhu/FlowRL)

* **Adapting Large Language Models via Reading Comprehension**  
  **Daixuan Cheng**, Shaohan Huang, Furu Wei  
  (**ICLR 2024 ‚Äî üåü The earliest research on domain adaptation of LLMs, üî• 500K+ downloads on Hugging Face, üèÜ #1 trending in domain LLMs, [ü§ó #2 Paper of the Day](https://huggingface.co/papers/2309.09530)**) [pdf](https://huggingface.co/papers/2309.09530) [code](https://github.com/microsoft/LMOps/tree/main/adaptllm) [huggingface](https://huggingface.co/AdaptLLM)

* **Instruction Pre-Training: Language Models are Supervised Multitask Learners**  
  **Daixuan Cheng**, Yuxian Gu, Shaohan Huang, Junyu Bi, Minlie Huang, Furu Wei  
  (**EMNLP 2024 (Main, Long Paper) ‚Äî LLM pre-training, [üåü recommended by Sebastian Raschka](https://magazine.sebastianraschka.com/p/instruction-pretraining-llms), üî• 200K+ downloads on Hugging Face, üèÜ #2 trending dataset, [ü§ó #2 Paper of the Day](https://huggingface.co/papers/2406.14491)**) [pdf](https://huggingface.co/papers/2406.14491) [code](https://github.com/microsoft/LMOps/tree/main/instruction_pretrain)

* **Uprise: Universal Prompt Retrieval for Improving Zero-Shot Evaluation**  
  **Daixuan Cheng**, Shaohan Huang, Junyu Bi, Yuefeng Zhan, Jianfeng Liu, Yujing Wang, Hao Sun, Furu Wei, Denvy Deng, Qi Zhang  
  (**EMNLP 2023 (Main, Long Paper) ‚Äî üåü Early investigation of RAG for LLMs, üî• [Top ML Papers of the Week (along with GPT-4)](https://x.com/dair_ai/status/1637456912596840448)**) [pdf](https://arxiv.org/abs/2303.08518) [code](https://github.com/microsoft/LMOps/tree/main/uprise)

* **On Domain-Adaptive Post-Training for Multimodal Large Language Models**  
  **Daixuan Cheng**, Shaohan Huang, Ziyu Zhu, Xintong Zhang, Wayne Xin Zhao, Zhongzhi Luan, Bo Dai, Zhenliang Zhang  
  (**EMNLP 2025 (Findings, Long Paper) ‚Äî üåü The earliest research on Domain adaptation of multimodal LLMs**) [pdf](https://arxiv.org/abs/2411.19930) [code](https://github.com/bigai-ai/QA-Synthesizer) [huggingface](https://huggingface.co/AdaptLLM/Adapt-MLLM-to-Domains)

* **How to Synthesize Text Data without Model Collapse?**  
  Xuekai Zhu, **Daixuan Cheng**, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou  
  (**ICML 2025 ‚Äî Synthetic data for LLMs**) [pdf](https://arxiv.org/abs/2412.14689) [code](https://github.com/Xuekai-Zhu/toedit)

* **VL-Match: Enhancing Vision-Language Pretraining with Token-Level and Instance-Level Matching**  
  Junyu Bi, **Daixuan Cheng**, Ping Yao, Bochen Pang, Yuefeng Zhan, Chuanguang Yang, Yujing Wang, Hao Sun, Weiwei Deng, Qi Zhang  
  (**ICCV 2023 ‚Äî Pre-training of vision-language models**) [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.pdf)

- **Snapshot-guided domain adaptation for ELECTRA**  
**Daixuan Cheng**, Shaohan Huang, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Furu Wei, Denvy Deng, Qi Zhang  
(**EMNLP 2022 (Findings, Short Paper) ‚Äî Domain Adaptation of LM**) [pdf](https://aclanthology.org/2022.findings-emnlp.163/)
