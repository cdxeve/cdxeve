# Daixuan Cheng

- I am a Ph.D. student at **Gaoling School of AI, Renmin University of China**, fortunately advised by [Wayne Xin Zhao](https://scholar.google.com/citations?user=JNhNacoAAAAJ&hl=en).  

- Ever since 2021, I have been a research student advised by [Shaohan Huang](https://buaahsh.github.io) and [Furu Wei](https://thegenerality.com) from the **GenAI Group of Microsoft Research**, with whom I have accomplished many of my representative works.

- I was previously a research assistant in the **CoAI Group, Tsinghua University**, fortunately advised by [Yuxian Gu](https://t1101675.github.io) and [Minlie Huang](https://scholar.google.com/citations?user=P1jPSzMAAAAJ&hl=zh-CN).  I also worked as a research engineer at BIGAI, fortunately collaborating with [Xuekai Zhu](https://xuekai-zhu.github.io/Xuekai-Zhu/).

**Recent Focus:**  
My current research emphasizes **Agent**, especially the **Generalization of Coding Agents**: [LLM-in-Sandbox](https://huggingface.co/papers/2601.16206).  
Feel free to reach out if you are interested in collaboration or discussions!

## Contact  
- Email: [daixuancheng6@gmail.com](mailto:daixuancheng6@gmail.com)
- WeChat: cdx18810357013

## Research Interests  

I am dedicated to enhancing **Large Language Models** across their entire lifecycle, **from Pre-Training to Agent**:  
- **General/Code Agent**: [LLM-in-Sandbox](https://huggingface.co/papers/2601.16206), [SWE-Master](https://huggingface.co/papers/2602.03411). 
- **Reasoning and Reinforcement Learning**: [Reasoning with Exploration](https://arxiv.org/abs/2506.14758), [FlowRL](https://huggingface.co/papers/2509.15207), [STILL](https://github.com/RUCAIBox/Slow_Thinking_with_LLMs).  
- **Pre-training**: [Instruction Pre-Training](https://huggingface.co/papers/2406.14491), [AdaptLLM](https://huggingface.co/papers/2309.09530), [VL-Match](https://openaccess.thecvf.com/content/ICCV2023/papers/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.pdf).  
- **Domain Adaptation (Mid-training)**: [AdaptLLM](https://huggingface.co/papers/2309.09530), [AdaMLLM](https://arxiv.org/abs/2411.19930), [SODA](https://aclanthology.org/2022.findings-emnlp.163/).  
- **Synthetic Data**: [Instruction Pre-Training](https://huggingface.co/papers/2406.14491), [AdaptLLM](https://huggingface.co/papers/2309.09530), [ToEdit](https://arxiv.org/abs/2412.14689).  
- **Retrieval Augmented Generation**: [UPRISE](https://arxiv.org/abs/2303.08518), [MDR](https://aclanthology.org/2024.naacl-long.235/).

## Selected Papers

*(Full list on [Google Scholar](https://scholar.google.com/citations?hl=en&user=flRAZJQAAAAJ&view_op=list_works))*
* **LLM-in-Sandbox Elicits General Agentic Intelligence**  
  **Daixuan Cheng**, Shaohan Huang, Yuxian Gu, Huatong Song, Guoxin Chen, Li Dong, Wayne Xin Zhao, Ji-Rong Wen, Furu Wei  
  (**arXiv preprint, 2026 â€”  General/Code Agent,  [ðŸ¤— #1 Paper of the Day](https://huggingface.co/papers/2601.16206),[Youtube with 335K+ views](https://www.youtube.com/shorts/9sjjLT2qyBE)**) [pdf](https://huggingface.co/papers/2601.16206) [project](https://llm-in-sandbox.github.io) [code](https://github.com/llm-in-sandbox/llm-in-sandbox)

* **Reasoning with Exploration: An Entropy Perspective**  
  **Daixuan Cheng**, Shaohan Huang, Xuekai Zhu, Bo Dai, Wayne Xin Zhao, Zhenliang Zhang, Furu Wei  
  (**AAAI 2026 â€”  Earliest Research on Exploration of RL in LLM reasoning, Relation between Entropy and Exploration, Significant Pass@K Gain**) [pdf](https://arxiv.org/abs/2506.14758)

* **FlowRL: Matching Reward Distributions for LLM Reasoning**  
  Xuekai Zhu, **Daixuan Cheng**, Dinghuai Zhang, Hengli Li, Kaiyan Zhang, Che Jiang, Youbang Sun, Ermo Hua, Yuxin Zuo, Xingtai Lv, Qizheng Zhang, Lin Chen, Fanghao Shao, Bo Xue, Yunchong Song, Zhenjie Yang, Ganqu Cui, Ning Ding, Jianfeng Gao, Xiaodong Liu, Bowen Zhou, Hongyuan Mei, Zhouhan Lin  
  (**ICLR 2026 â€” Exploration of RL in LLM reasoning, [ðŸ¤— #1 Paper of the Day](https://huggingface.co/papers/2509.15207), [Recipe at VERL](https://github.com/volcengine/verl/tree/main/recipe/flowrl)**) [pdf](https://huggingface.co/papers/2509.15207) [code](https://github.com/Xuekai-Zhu/FlowRL)

* **Adapting Large Language Models via Reading Comprehension**  
  **Daixuan Cheng**, Shaohan Huang, Furu Wei  
  (**ICLR 2024 â€”  Earliest Research on Domain LLMs, 500K+ Downloads on Hugging Face, [#1 Trending of ALL Domain LLMs on Huggingface](https://huggingface.co/AdaptLLM), [ðŸ¤— #2 Paper of the Day](https://huggingface.co/papers/2309.09530)**) [pdf](https://huggingface.co/papers/2309.09530) [code](https://github.com/microsoft/LMOps/tree/main/adaptllm) [huggingface](https://huggingface.co/AdaptLLM)

* **Instruction Pre-Training: Language Models are Supervised Multitask Learners**  
  **Daixuan Cheng**, Yuxian Gu, Shaohan Huang, Junyu Bi, Minlie Huang, Furu Wei  
  (**EMNLP 2024 (Main, Long Paper) â€” LLM Pre-training, Earliest Research on Mid-training, [ Recommended by Sebastian Raschka](https://magazine.sebastianraschka.com/p/instruction-pretraining-llms),  200K+ Downloads on Hugging Face, [#2 Trending of ALL Huggingface Datasets](https://huggingface.co/instruction-pretrain), [ðŸ¤— #2 Paper of the Day](https://huggingface.co/papers/2406.14491)**) [pdf](https://huggingface.co/papers/2406.14491) [code](https://github.com/microsoft/LMOps/tree/main/instruction_pretrain)

* **Uprise: Universal Prompt Retrieval for Improving Zero-Shot Evaluation**  
  **Daixuan Cheng**, Shaohan Huang, Junyu Bi, Yuefeng Zhan, Jianfeng Liu, Yujing Wang, Hao Sun, Furu Wei, Denvy Deng, Qi Zhang  
  (**EMNLP 2023 (Main, Long Paper) â€” Early Research on RAG for LLMs, [Top ML Papers of the Week (along with GPT-4)](https://x.com/dair_ai/status/1637456912596840448)**) [pdf](https://arxiv.org/abs/2303.08518) [code](https://github.com/microsoft/LMOps/tree/main/uprise)

* **On Domain-Adaptive Post-Training for Multimodal Large Language Models**  
  **Daixuan Cheng**, Shaohan Huang, Ziyu Zhu, Xintong Zhang, Wayne Xin Zhao, Zhongzhi Luan, Bo Dai, Zhenliang Zhang  
  (**EMNLP 2025 (Findings, Long Paper) â€” Earliest Research on Domain MLLMs**) [pdf](https://arxiv.org/abs/2411.19930) [code](https://github.com/bigai-ai/QA-Synthesizer) [huggingface](https://huggingface.co/AdaptLLM/Adapt-MLLM-to-Domains)

* **How to Synthesize Text Data without Model Collapse?**  
  Xuekai Zhu, **Daixuan Cheng**, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou  
  (**ICML 2025 â€” Synthetic data for LLMs**) [pdf](https://arxiv.org/abs/2412.14689) [code](https://github.com/Xuekai-Zhu/toedit)

* **VL-Match: Enhancing Vision-Language Pretraining with Token-Level and Instance-Level Matching**  
  Junyu Bi, **Daixuan Cheng**, Ping Yao, Bochen Pang, Yuefeng Zhan, Chuanguang Yang, Yujing Wang, Hao Sun, Weiwei Deng, Qi Zhang  
  (**ICCV 2023 â€” Pre-training of Vision-language Models**) [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.pdf)

- **Snapshot-guided domain adaptation for ELECTRA**  
**Daixuan Cheng**, Shaohan Huang, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Furu Wei, Denvy Deng, Qi Zhang  
(**EMNLP 2022 (Findings, Short Paper) â€” Domain Adaptation of LM**) [pdf](https://aclanthology.org/2022.findings-emnlp.163/)

## Education

- **Ph.D. Student in Artificial Intelligence**, Gaoling School of AI, Renmin University of China (2025 â€“ Present)  
  - Advisor: [Xin Zhao](https://scholar.google.com/citations?user=JNhNacoAAAAJ&hl=en)

- **M.S. in Computer Science**, School of Computer Science, Beijing University of Posts and Telecommunications (2020 â€“ 2023)  
  - Advisor: [Haifeng Sun](https://hfsun.github.io)

- **B.S. in Communication Engineering**, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications (2016 â€“ 2020)  

## Honors & Awards 
* **[ðŸ¤— Hugging Face Top Contributors](https://x.com/i/lists/1762103087395693000)**
* **[Outstanding Reviewer of EMNLP (Top 0.5%)](https://aclanthology.org/2025.emnlp-main.0.pdf)**
* **1st Place in the PhD Entrance Exam (Preliminary) at the GSAI, Renmin University of China**
* **National Scholarship for Master Students (Top 1%)**
* **1st Prize in the National English Competition (Top 0.5%)**
